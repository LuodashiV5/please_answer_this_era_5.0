我们使用 OpenClaw 习惯于布置任务、等结果、再循环，例如整理笔记、查资料、定时资讯、编程 Coding。 似乎执行是唯一的用法。

但 OpenClaw 能做的，远不止这些。

每次交互，它都在积累你的信息：你的工作节奏、你反复踩的坑、你每次在哪个节点卡住、你最高频的决策类型。这些不是碎片，是关于你这个人的模式。

**用好了，它是一个随时间复利的智能搭档。** 用不好，它就是一个体面一点的打杂工。

差距在哪里？在于你有没有让它反过来审视你：帮你挖出你自己都没意识到的盲区和机会。这不复杂。21 个问题，就能让 OpenClaw 从"等你下指令"切换到"主动替你想"。

---

## 为什么会这样？

有三个原因。

**第一，AI 的默认角色是执行者。** 它被训练成回答你提的问题、完成你布置的任务。除非你明确要求，否则它不会主动切换到"审视者"模式。

**第二，压缩机制制造了"它懂我"的幻觉。** 每次会话结束，上下文被压缩或丢失。你以为它记住了你，其实它每次都在重建对你的理解——而且没人告诉它哪里重建错了。

**第三，没人教过我们该问什么。** "你对我有哪些假设可能是错的？"——这种元层级的问题，超出了大多数人的默认使用框架。

你在给 AI 打工，而不是让 AI 替你想，那要如何解决？

---

## 21 个问题挖出你的金子

这 21 个问题的使用效果，建立在一个基础上：**OpenClaw 已经对你积累了足够的上下文。**

如果你刚开始用，或者只是偶尔丢几个任务进去，那么 AI 没有足够的素材来给出真正针对你的回答。你问"我哪里在浪费时间"，它只能给你通用建议，跟让 ChatGPT 随手回答没有本质区别。

**这 21 个问题不是入门操作，是进阶工具。**

建议先真实使用 2-4 周，让它见识你足够多的任务、决策、工作习惯。等到感觉它"开始了解你了"，再来用这些问题——这时候得到的答案，才会是"哦，它真的在说我"，而不是"这不就是 AI 套话吗"。

以下是 21 条提示词（原版为英文，来自 X 上的 @kloss_xyz ）的中文场景化版本：

```markdown
1. 从你目前对我和我工作流的了解来看，我缺少哪些工具或自动化，   
补上之后能明显改善我现在的运作方式？
2. 你对我、我的优先级或者我的偏好，现在有哪些假设可能是错的？   
我们现在就核实并纠正。
3. 基于你见过的我所有决策模式和需求，我下周或者未来可能需要什么——  
 你现在就可以提前准备和系统化？
4. 根据我的项目走向和你对我的了解，你
现在应该主动去发展和补充哪些能力？
5. 关于我的目标、风格或优先级，哪些上下文在会话间被压缩丢失了——   
需要明确修复，否则你会越来越"退步"？
6. 我的项目、想法或目标之间，你看到了哪些我自己可能还没意识到的关联？   
基于这些关联，我们应该构建或调整什么？
7. 你观察到我工作中哪些反复出现的摩擦点，可以通过构建新的工作流、   
模板或自动化来消除——不需要我每次开口要求？
8. 从我给过你的所有纠正、调整和反馈来看，你现在应该把哪些规则写进   
你自己的身份或技能文件，从此不再重蹈覆辙？
9. 如果你审计一下上周为我做的所有事情，哪些真正推动了我的目标——   
哪些是我们应该永久砍掉的无效动作？
10. 你明明对我有足够的了解，却在哪些地方还在输出通用答案，    
而不是真正为我量身定制的内容？
11. 你现在可以为自己构建一个什么样的系统，让它的价值持续积累，    
让你未来帮我做的每一件事都更快、更准？
12. 你犯过哪些超过一次的错误或错失了哪些机会？    
我们可以一起建立什么自检机制，确保它们不再发生？
13. 基于你对我整体生态走向的了解，你现在应该主动去研究、学习或测试什么——    
不需要我告诉你？
14. 你在对我和我项目的了解中，哪些地方是在用假设填空，    
而不是及时提出来让我们锁定真实答案？
15. 在你的记忆和上下文文件里，有哪些最有价值的数据、洞察或规律——    
被你一直闲置、没有充分用来帮我？
16. 如果给你对我的优先级、目标和思维方式的建模打 1-10 分，    
你会打几分？什么在拖分？具体怎么提升？
17. 有哪些外部信息源是你应该持续获取的，或者我可以主动提供给你，    
让你处理我的项目时判断更准？18. 如果明天换一个全新的 Agent，只靠我的文档接手你的工作，    
它会在哪些关键地方犯错——而这些是你通过实际合作才摸清楚的？    我们怎么把这些知识永久固化进系统？
19. 我还在手动处理或低效完成的哪些工作流，你其实已经有足够的上下文    
来完全接管或优化——只差我点头？
20. 基于我们合作以来我的思维和优先级的演变，    
你现在哪些处理方式已经过时，需要重建？
21. 接下来 24 小时内，你能做的单一最高杠杆的事是什么——    
不需要我开口，但能实质性加速我前进的方向？
```

---

## 这 21 条背后的逻辑

这个 21 个问题大致分为 4 个方向。

**逼出 AI 对你的隐性假设**（2、14、16）：AI 一直在用它"以为正确"的假设处理你的任务，但从不主动说出来。这类问题强迫它把假设显性化，你才能纠正偏差。问题 16 最直接：让它给自己打分，说出哪里不准。AI 很难在这里糊弄你，因为你要的是数字和原因。

**用你看不见的视角挖规律**（5、6、9、10、15）：你只能看到你完成的事，AI 见过了全部。这类问题让它调出"完整记录"，告诉你哪些动作是无效重复、哪些项目之间有你没发现的关联。问题 9 是沉默杀伤力最强的一个——很多人问完会沉默一下，因为答案往往是：自以为在推进的事，有一半是原地转圈。

**把 AI 从等你下指令，变成主动往前推**（1、3、4、13、17、21）：不是问"帮我做 X"，而是问"基于你对我的了解，X 是什么"。问题 21 最直接：接下来 24 小时，你能做的最高杠杆的事是什么，不需要我开口。第一次问这个，有点像第一次让助理来安排你的日程——需要一点信任，但跑通之后你会发现它能看到你看不到的优先级。

**让洞察沉淀成系统，不聊完就蒸发**（7、8、11、12、18、19、20）：这是 21 条里复利最强的部分。AI 说出了你的问题，聊完关掉对话，下次开新会话又忘了。这类问题要求它把发现落地成文件、规则、工作流、Memory 更新。只有写进系统的东西，才是真正留下来的东西。

当然，如果这些问题的回答中有不符合自己的人设和行为的，那可能是被污染了，就要选择性调整了，避免错上加错。

---
## 怎么用

别一次性把 21 条全丢进去。
选一个你最有感觉的方向，挑 1-2 条问，让它认真回答。如果它给的是泛泛的"观察"，追一句：**"给我一个具体的可执行建议，以及你要把它写进哪个文件。"**
问完不落地，等于白问。

---
大多数人在想怎么让 AI 更快——更好的提示词、更新的模型、更贵的会员。
很少有人在问：**怎么让 AI 更懂我这个人。**
这才是真正的差距。
你的 OpenClaw 已经在那里了。问它。


这篇文章揭示了一个关键转变：让AI从"执行工具"升级为"智能搭档"的核心，在于主动引导它审视你。文中21个问题分为四类：逼出AI的隐性假设、挖掘你没发现的工作规律、促使AI主动推进事项、将洞察固化为系统。使用前提是先让AI积累2-4周真实工作数据，当它开始理解你的决策模式后，这些问题才能触发个性化反馈。真正的差距不在于更快的模型，而在于"怎么让AI更懂我这个人"——这才是人机协作的终极杠杆点。
